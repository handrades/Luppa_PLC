# Prometheus Configuration for Luppa PLC Inventory System
# Configured for production monitoring with comprehensive service discovery

global:
  # How frequently to scrape targets by default
  scrape_interval: 15s
  
  # How long until a scrape request times out
  scrape_timeout: 10s
  
  # How frequently to evaluate rules
  evaluation_interval: 15s
  
  # External labels to add to any time series or alerts
  external_labels:
    monitor: 'luppa-monitor'
    environment: 'production'

# Alertmanager configuration (can be added when alertmanager is deployed)
# alerting:
#   alertmanagers:
#     - static_configs:
#         - targets:
#           - alertmanager:9093

# Load rules once and periodically evaluate them
rule_files:
  - "rules/*.yml"

# Scrape configuration
scrape_configs:
  # Prometheus itself
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
    scrape_interval: 15s
    metrics_path: /metrics

  # API application metrics
  - job_name: 'api'
    static_configs:
      - targets: ['api:9090']
    scrape_interval: 15s
    metrics_path: /metrics
    scrape_timeout: 10s
    honor_labels: false
    params:
      format: ['prometheus']
    metric_relabel_configs:
      # Add service label
      - source_labels: [__name__]
        target_label: service
        replacement: api
      # Drop high cardinality metrics if needed
      - source_labels: [__name__]
        regex: 'http_request_duration_seconds_bucket'
        target_label: __tmp_drop_bucket
        replacement: 'true'

  # PostgreSQL metrics (via postgres_exporter)
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']
    scrape_interval: 30s
    scrape_timeout: 10s
    # Note: postgres_exporter would need to be added as a separate service
    # For now, we'll monitor via the API health checks

  # Redis metrics (via redis_exporter)
  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    scrape_interval: 30s
    scrape_timeout: 10s
    # Note: redis_exporter would need to be added as a separate service
    # For now, we'll monitor via the API health checks

  # Nginx metrics (via nginx-prometheus-exporter)
  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx:80']
    scrape_interval: 30s
    scrape_timeout: 10s
    metrics_path: /nginx_status
    # Note: nginx stub_status module would need to be enabled

  # Node/System metrics (via node_exporter if deployed)
  - job_name: 'node'
    static_configs:
      - targets: []  # Add node_exporter targets when available
    scrape_interval: 15s
    scrape_timeout: 10s

  # Docker/Container metrics (via cAdvisor if deployed)
  - job_name: 'cadvisor'
    static_configs:
      - targets: []  # Add cAdvisor targets when available
    scrape_interval: 30s
    scrape_timeout: 10s

  # Custom health check endpoints
  - job_name: 'health-checks'
    static_configs:
      - targets: 
          - 'api:3000'
          - 'nginx:80'
    scrape_interval: 30s
    scrape_timeout: 5s
    metrics_path: /health
    params:
      format: ['json']
    metric_relabel_configs:
      # Convert health check responses to metrics
      - source_labels: [__name__]
        target_label: __name__
        regex: 'up'
        replacement: 'service_up'

  # Grafana metrics
  - job_name: 'grafana'
    static_configs:
      - targets: ['grafana:3000']
    scrape_interval: 30s
    scrape_timeout: 10s
    metrics_path: /api/health

# Storage configuration
storage:
  tsdb:
    # Retention policies
    retention.time: 30d
    retention.size: 10GB
    
    # Block configuration
    block.duration: 2h
    
    # Compaction configuration
    compaction.block_range.max: 744h  # 31 days

# Remote write configuration (for external systems if needed)
# remote_write:
#   - url: "http://remote-prometheus:9090/api/v1/write"
#     queue_config:
#       max_samples_per_send: 1000
#       max_shards: 200
#       capacity: 2500

# Remote read configuration (for external systems if needed)
# remote_read:
#   - url: "http://remote-prometheus:9090/api/v1/read"
