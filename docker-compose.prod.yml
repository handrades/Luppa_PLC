networks:
  luppa-prod:
    driver: overlay
    name: luppa-prod-network
    attachable: false
    encrypted: true
  luppa-monitoring:
    driver: overlay
    name: luppa-monitoring-network
    attachable: false
    encrypted: true

volumes:
  postgres-data:
    name: luppa-postgres-data
  redis-data:
    name: luppa-redis-data
  grafana-data:
    name: luppa-grafana-data
  prometheus-data:
    name: luppa-prometheus-data
  ssl-certs:
    name: luppa-ssl-certs

configs:
  nginx-config:
    file: ./infrastructure/nginx/nginx.prod.conf
  prometheus-config:
    file: ./infrastructure/monitoring/prometheus/prometheus.yml
  grafana-config:
    file: ./infrastructure/monitoring/grafana/grafana.ini

secrets:
  postgres-password:
    external: true
  redis-password:
    external: true
  jwt-secret:
    external: true
  ssl-cert:
    external: true
  ssl-key:
    external: true

services:
  postgres:
    image: postgres:17
    networks:
      - luppa-prod
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-luppa_prod}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD_FILE: /run/secrets/postgres-password
      POSTGRES_HOST_AUTH_METHOD: ${POSTGRES_HOST_AUTH_METHOD:-scram-sha-256}
      POSTGRES_INITDB_ARGS: "--auth-host=scram-sha-256 --auth-local=scram-sha-256"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./infrastructure/postgres/initdb:/docker-entrypoint-initdb.d:ro
    secrets:
      - postgres-password
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres} -d ${POSTGRES_DB:-luppa_prod}"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '0.5'
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3

  pgbouncer:
    image: pgbouncer/pgbouncer:1.23
    networks:
      - luppa-prod
    environment:
      DATABASES_HOST: postgres
      DATABASES_PORT: 5432
      DATABASES_USER: ${POSTGRES_USER:-postgres}
      DATABASES_PASSWORD_FILE: /run/secrets/postgres-password
      DATABASES_DBNAME: ${POSTGRES_DB:-luppa_prod}
      POOL_MODE: transaction
      MAX_CLIENT_CONN: 100
      DEFAULT_POOL_SIZE: 25
      MIN_POOL_SIZE: 5
      RESERVE_POOL_SIZE: 5
      SERVER_RESET_QUERY: DISCARD ALL
      IGNORE_STARTUP_PARAMETERS: extra_float_digits
    secrets:
      - postgres-password
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 5432 || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.1'
      restart_policy:
        condition: on-failure

  redis:
    image: redis:8-alpine
    networks:
      - luppa-prod
    command: >
      redis-server
      --requirepass_file /run/secrets/redis-password
      --appendonly yes
      --appendfsync everysec
      --auto-aof-rewrite-percentage 100
      --auto-aof-rewrite-min-size 64mb
      --maxmemory ${REDIS_MAX_MEMORY:-1gb}
      --maxmemory-policy ${REDIS_EVICTION_POLICY:-allkeys-lru}
      --save 900 1
      --save 300 10
      --save 60 10000
      --tcp-keepalive 300
      --timeout 0
    volumes:
      - redis-data:/data
    secrets:
      - redis-password
    healthcheck:
      test: ["CMD", "redis-cli", "--no-auth-warning", "-a", "$(cat /run/secrets/redis-password)", "ping"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.25'
      restart_policy:
        condition: on-failure

  api:
    image: ${DOCKER_REGISTRY:-}luppa-api:${API_VERSION:-latest}
    networks:
      - luppa-prod
      - luppa-monitoring
    environment:
      NODE_ENV: production
      PORT: ${API_PORT:-3000}
      HOST: 0.0.0.0
      LOG_LEVEL: ${LOG_LEVEL:-info}
      POSTGRES_HOST: pgbouncer
      POSTGRES_PORT: 5432
      POSTGRES_DB: ${POSTGRES_DB:-luppa_prod}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_SSL: ${POSTGRES_SSL:-false}
      REDIS_HOST: redis
      REDIS_PORT: 6379
      CORS_ORIGIN: ${CORS_ORIGIN:-https://localhost}
      SESSION_SECRET_FILE: /run/secrets/jwt-secret
      METRICS_PORT: 9090
      METRICS_PATH: /metrics
    secrets:
      - jwt-secret
    depends_on:
      pgbouncer:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:${API_PORT:-3000}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
        order: start-first

  web:
    image: ${DOCKER_REGISTRY:-}luppa-web:${WEB_VERSION:-latest}
    networks:
      - luppa-prod
    environment:
      NODE_ENV: production
      VITE_API_BASE_URL: ${VITE_API_BASE_URL:-https://localhost/api}
      VITE_APP_VERSION: ${VITE_APP_VERSION:-latest}
      VITE_LOG_LEVEL: ${VITE_LOG_LEVEL:-warn}
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:80"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
      restart_policy:
        condition: on-failure
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback

  nginx:
    image: nginx:1.27-alpine
    networks:
      - luppa-prod
    ports:
      - "${NGINX_HTTP_PORT:-80}:80"
      - "${NGINX_HTTPS_PORT:-443}:443"
    volumes:
      - ssl-certs:/etc/ssl/certs:ro
    configs:
      - source: nginx-config
        target: /etc/nginx/nginx.conf
        mode: 0444
    secrets:
      - source: ssl-cert
        target: /etc/ssl/certs/server.crt
        mode: 0444
      - source: ssl-key
        target: /etc/ssl/private/server.key
        mode: 0400
    depends_on:
      - api
      - web
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.25'
      restart_policy:
        condition: on-failure

  prometheus:
    image: prom/prometheus:v3.0.1
    networks:
      - luppa-monitoring
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--storage.tsdb.retention.size=10GB'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
      - '--log.level=info'
    volumes:
      - prometheus-data:/prometheus
      - ./infrastructure/monitoring/prometheus/rules:/etc/prometheus/rules:ro
    configs:
      - source: prometheus-config
        target: /etc/prometheus/prometheus.yml
        mode: 0444
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
      restart_policy:
        condition: on-failure

  grafana:
    image: grafana/grafana:11.4.0
    networks:
      - luppa-monitoring
      - luppa-prod
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin}
      GF_SECURITY_SECRET_KEY: ${GRAFANA_SECRET_KEY}
      GF_USERS_ALLOW_SIGN_UP: false
      GF_INSTALL_PLUGINS: ${GRAFANA_INSTALL_PLUGINS:-}
      GF_SECURITY_DISABLE_GRAVATAR: true
      GF_ANALYTICS_REPORTING_ENABLED: false
      GF_ANALYTICS_CHECK_FOR_UPDATES: false
      GF_LOG_LEVEL: info
      GF_SERVER_DOMAIN: ${GRAFANA_DOMAIN:-localhost}
      GF_SERVER_ROOT_URL: https://${GRAFANA_DOMAIN:-localhost}/grafana/
      GF_SERVER_SERVE_FROM_SUB_PATH: true
    volumes:
      - grafana-data:/var/lib/grafana
      - ./infrastructure/monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./infrastructure/monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    configs:
      - source: grafana-config
        target: /etc/grafana/grafana.ini
        mode: 0444
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'
      restart_policy:
        condition: on-failure
